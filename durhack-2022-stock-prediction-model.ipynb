{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# QRT Stock Prediction Model\n\nThis notebook illustrates a test for the stock prediction model\n\n## Used libraries","metadata":{}},{"cell_type":"code","source":"import seaborn as sns # importing libraries\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-11-20T10:46:18.343286Z","iopub.execute_input":"2022-11-20T10:46:18.343733Z","iopub.status.idle":"2022-11-20T10:46:18.349548Z","shell.execute_reply.started":"2022-11-20T10:46:18.343696Z","shell.execute_reply":"2022-11-20T10:46:18.348741Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"markdown","source":"## Loading data\n\nThe train and test inputs are composed of 46 features.\n\nThe target of this challenge is `RET` and corresponds to the fact that the **return is in the top 50% of highest stock returns**.\n\nSince the median is very close to 0, this information should not change much with the idea to predict the sign of the return.","metadata":{}},{"cell_type":"code","source":"x_train = pd.read_csv('../input/qrtdataset/x_train_Lafd4AH.csv', index_col='ID')\ny_train = pd.read_csv('../input/qrtdataset/y_train_JQU4vbI.csv', index_col='ID')\ntrain = pd.concat([x_train, y_train], axis=1)\ntest = pd.read_csv('../input/qrtdataset/x_test_c7ETL4q.csv', index_col='ID') #reading in training and test data\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T10:46:18.350964Z","iopub.execute_input":"2022-11-20T10:46:18.351639Z","iopub.status.idle":"2022-11-20T10:46:24.212641Z","shell.execute_reply.started":"2022-11-20T10:46:18.351606Z","shell.execute_reply":"2022-11-20T10:46:24.211576Z"},"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"    DATE  STOCK  INDUSTRY  INDUSTRY_GROUP  SECTOR  SUB_INDUSTRY     RET_1  \\\nID                                                                          \n0      0      2        18               5       3            44 -0.015748   \n1      0      3        43              15       6           104  0.003984   \n2      0      4        57              20       8           142  0.000440   \n3      0      8         1               1       1             2  0.031298   \n4      0     14        36              12       5            92  0.027273   \n\n    VOLUME_1     RET_2  VOLUME_2  ...  VOLUME_16    RET_17  VOLUME_17  \\\nID                                ...                                   \n0   0.147931 -0.015504  0.179183  ...   0.630899  0.003254  -0.379412   \n1        NaN -0.090580       NaN  ...        NaN  0.003774        NaN   \n2  -0.096282 -0.058896  0.084771  ...  -0.010336 -0.017612  -0.354333   \n3  -0.429540  0.007756 -0.089919  ...   0.012105  0.033824  -0.290178   \n4  -0.847155 -0.039302 -0.943033  ...  -0.277083 -0.012659   0.139086   \n\n      RET_18  VOLUME_18    RET_19  VOLUME_19    RET_20  VOLUME_20    RET  \nID                                                                        \n0   0.008752  -0.110597 -0.012959   0.174521 -0.002155  -0.000937   True  \n1  -0.018518        NaN -0.028777        NaN -0.034722        NaN   True  \n2  -0.006562  -0.519391 -0.012101  -0.356157 -0.006867  -0.308868  False  \n3  -0.001468  -0.663834 -0.013520  -0.562126 -0.036745  -0.631458  False  \n4   0.004237  -0.017547  0.004256   0.579510 -0.040817   0.802806  False  \n\n[5 rows x 47 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATE</th>\n      <th>STOCK</th>\n      <th>INDUSTRY</th>\n      <th>INDUSTRY_GROUP</th>\n      <th>SECTOR</th>\n      <th>SUB_INDUSTRY</th>\n      <th>RET_1</th>\n      <th>VOLUME_1</th>\n      <th>RET_2</th>\n      <th>VOLUME_2</th>\n      <th>...</th>\n      <th>VOLUME_16</th>\n      <th>RET_17</th>\n      <th>VOLUME_17</th>\n      <th>RET_18</th>\n      <th>VOLUME_18</th>\n      <th>RET_19</th>\n      <th>VOLUME_19</th>\n      <th>RET_20</th>\n      <th>VOLUME_20</th>\n      <th>RET</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n      <td>18</td>\n      <td>5</td>\n      <td>3</td>\n      <td>44</td>\n      <td>-0.015748</td>\n      <td>0.147931</td>\n      <td>-0.015504</td>\n      <td>0.179183</td>\n      <td>...</td>\n      <td>0.630899</td>\n      <td>0.003254</td>\n      <td>-0.379412</td>\n      <td>0.008752</td>\n      <td>-0.110597</td>\n      <td>-0.012959</td>\n      <td>0.174521</td>\n      <td>-0.002155</td>\n      <td>-0.000937</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>3</td>\n      <td>43</td>\n      <td>15</td>\n      <td>6</td>\n      <td>104</td>\n      <td>0.003984</td>\n      <td>NaN</td>\n      <td>-0.090580</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.003774</td>\n      <td>NaN</td>\n      <td>-0.018518</td>\n      <td>NaN</td>\n      <td>-0.028777</td>\n      <td>NaN</td>\n      <td>-0.034722</td>\n      <td>NaN</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>4</td>\n      <td>57</td>\n      <td>20</td>\n      <td>8</td>\n      <td>142</td>\n      <td>0.000440</td>\n      <td>-0.096282</td>\n      <td>-0.058896</td>\n      <td>0.084771</td>\n      <td>...</td>\n      <td>-0.010336</td>\n      <td>-0.017612</td>\n      <td>-0.354333</td>\n      <td>-0.006562</td>\n      <td>-0.519391</td>\n      <td>-0.012101</td>\n      <td>-0.356157</td>\n      <td>-0.006867</td>\n      <td>-0.308868</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.031298</td>\n      <td>-0.429540</td>\n      <td>0.007756</td>\n      <td>-0.089919</td>\n      <td>...</td>\n      <td>0.012105</td>\n      <td>0.033824</td>\n      <td>-0.290178</td>\n      <td>-0.001468</td>\n      <td>-0.663834</td>\n      <td>-0.013520</td>\n      <td>-0.562126</td>\n      <td>-0.036745</td>\n      <td>-0.631458</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>14</td>\n      <td>36</td>\n      <td>12</td>\n      <td>5</td>\n      <td>92</td>\n      <td>0.027273</td>\n      <td>-0.847155</td>\n      <td>-0.039302</td>\n      <td>-0.943033</td>\n      <td>...</td>\n      <td>-0.277083</td>\n      <td>-0.012659</td>\n      <td>0.139086</td>\n      <td>0.004237</td>\n      <td>-0.017547</td>\n      <td>0.004256</td>\n      <td>0.579510</td>\n      <td>-0.040817</td>\n      <td>0.802806</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 47 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering\n\nThe main drawback in this challenge would be to deal with the noise. To do that, we could create some feature that aggregate features with some statistics. \n\nThe following cell computes statistics on a given target conditionally to some features. For example, we want to generate a feature that describe the mean of `RET_1` conditionally to the `SECTOR` and the `DATE`.\n\n**Ideas of improvement**: change shifts, the conditional features, the statistics, and the target. ","metadata":{}},{"cell_type":"code","source":"# Feature engineering\nnew_features = []\n\n# Conditional aggregated features\nshifts = [1]  # Choose some different shifts\nstatistics = ['max']  # the type of stat \ngb_features = [['SECTOR'],['DATE'],['INDUSTRY']]\nfor gb_f in gb_features:\n    target_feature = 'RET'\n    tmp_name = '_'.join(gb_f)\n    for shift in shifts:\n        for stat in statistics:\n            name = f'{target_feature}_{shift}_{tmp_name}_{stat}'\n            feat = f'{target_feature}_{shift}'\n            new_features.append(name)\n            for data in [train, test]:\n                data[name] = data.groupby(gb_f)[feat].transform(stat)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T10:46:24.215048Z","iopub.execute_input":"2022-11-20T10:46:24.215644Z","iopub.status.idle":"2022-11-20T10:46:24.274263Z","shell.execute_reply.started":"2022-11-20T10:46:24.215600Z","shell.execute_reply":"2022-11-20T10:46:24.273326Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"markdown","source":"## Feature selection\n\nTo reduce the number of feature (and the noise) we only consider the 5 last days of `RET` and `VOLUME` in addition to the newly created feature.","metadata":{}},{"cell_type":"code","source":"target = 'RET'\n\nn_shifts = 20 # using all shifts for optimal accuracy\nfeatures = ['RET_%d' % (i + 1) for i in range(n_shifts)]\nfeatures += ['VOLUME_%d' % (i + 1) for i in range(n_shifts)]\nfeatures += new_features  # The conditional features\ntrain[features].head()","metadata":{"execution":{"iopub.status.busy":"2022-11-20T10:46:24.275520Z","iopub.execute_input":"2022-11-20T10:46:24.276436Z","iopub.status.idle":"2022-11-20T10:46:24.443572Z","shell.execute_reply.started":"2022-11-20T10:46:24.276391Z","shell.execute_reply":"2022-11-20T10:46:24.442428Z"},"trusted":true},"execution_count":134,"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"       RET_1     RET_2     RET_3     RET_4     RET_5     RET_6     RET_7  \\\nID                                                                         \n0  -0.015748 -0.015504  0.010972 -0.014672  0.016483  0.014331 -0.017215   \n1   0.003984 -0.090580  0.018826 -0.025540 -0.038062 -0.006873 -0.026756   \n2   0.000440 -0.058896 -0.009042  0.024852  0.009354  0.027522 -0.023047   \n3   0.031298  0.007756 -0.004632 -0.019677  0.003544 -0.002021 -0.043962   \n4   0.027273 -0.039302  0.000000  0.000000  0.022321  0.018182 -0.026549   \n\n       RET_8     RET_9    RET_10  ...  VOLUME_14  VOLUME_15  VOLUME_16  \\\nID                                ...                                    \n0  -0.018433  0.134146  0.182287  ...  -2.042624  -0.369605   0.630899   \n1   0.023973  0.158731  0.045642  ...        NaN        NaN        NaN   \n2  -0.002979 -0.006342  0.055803  ...  -0.356711  -0.336773  -0.010336   \n3  -0.004329  0.014146 -0.021946  ...  -2.144763  -0.431029   0.012105   \n4  -0.017391 -0.008621  0.022026  ...  18.894266   0.803608  -0.277083   \n\n    VOLUME_17  VOLUME_18  VOLUME_19  VOLUME_20  RET_1_SECTOR_max  \\\nID                                                                 \n0   -0.379412  -0.110597   0.174521  -0.000937          0.642105   \n1         NaN        NaN        NaN        NaN          1.444990   \n2   -0.354333  -0.519391  -0.356157  -0.308868          1.422681   \n3   -0.290178  -0.663834  -0.562126  -0.631458          0.636363   \n4    0.139086  -0.017547   0.579510   0.802806          0.490869   \n\n    RET_1_DATE_max  RET_1_INDUSTRY_max  \nID                                      \n0         0.314424            0.238169  \n1         0.314424            1.444990  \n2         0.314424            0.570665  \n3         0.314424            0.246883  \n4         0.314424            0.261921  \n\n[5 rows x 43 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RET_1</th>\n      <th>RET_2</th>\n      <th>RET_3</th>\n      <th>RET_4</th>\n      <th>RET_5</th>\n      <th>RET_6</th>\n      <th>RET_7</th>\n      <th>RET_8</th>\n      <th>RET_9</th>\n      <th>RET_10</th>\n      <th>...</th>\n      <th>VOLUME_14</th>\n      <th>VOLUME_15</th>\n      <th>VOLUME_16</th>\n      <th>VOLUME_17</th>\n      <th>VOLUME_18</th>\n      <th>VOLUME_19</th>\n      <th>VOLUME_20</th>\n      <th>RET_1_SECTOR_max</th>\n      <th>RET_1_DATE_max</th>\n      <th>RET_1_INDUSTRY_max</th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.015748</td>\n      <td>-0.015504</td>\n      <td>0.010972</td>\n      <td>-0.014672</td>\n      <td>0.016483</td>\n      <td>0.014331</td>\n      <td>-0.017215</td>\n      <td>-0.018433</td>\n      <td>0.134146</td>\n      <td>0.182287</td>\n      <td>...</td>\n      <td>-2.042624</td>\n      <td>-0.369605</td>\n      <td>0.630899</td>\n      <td>-0.379412</td>\n      <td>-0.110597</td>\n      <td>0.174521</td>\n      <td>-0.000937</td>\n      <td>0.642105</td>\n      <td>0.314424</td>\n      <td>0.238169</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.003984</td>\n      <td>-0.090580</td>\n      <td>0.018826</td>\n      <td>-0.025540</td>\n      <td>-0.038062</td>\n      <td>-0.006873</td>\n      <td>-0.026756</td>\n      <td>0.023973</td>\n      <td>0.158731</td>\n      <td>0.045642</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.444990</td>\n      <td>0.314424</td>\n      <td>1.444990</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000440</td>\n      <td>-0.058896</td>\n      <td>-0.009042</td>\n      <td>0.024852</td>\n      <td>0.009354</td>\n      <td>0.027522</td>\n      <td>-0.023047</td>\n      <td>-0.002979</td>\n      <td>-0.006342</td>\n      <td>0.055803</td>\n      <td>...</td>\n      <td>-0.356711</td>\n      <td>-0.336773</td>\n      <td>-0.010336</td>\n      <td>-0.354333</td>\n      <td>-0.519391</td>\n      <td>-0.356157</td>\n      <td>-0.308868</td>\n      <td>1.422681</td>\n      <td>0.314424</td>\n      <td>0.570665</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.031298</td>\n      <td>0.007756</td>\n      <td>-0.004632</td>\n      <td>-0.019677</td>\n      <td>0.003544</td>\n      <td>-0.002021</td>\n      <td>-0.043962</td>\n      <td>-0.004329</td>\n      <td>0.014146</td>\n      <td>-0.021946</td>\n      <td>...</td>\n      <td>-2.144763</td>\n      <td>-0.431029</td>\n      <td>0.012105</td>\n      <td>-0.290178</td>\n      <td>-0.663834</td>\n      <td>-0.562126</td>\n      <td>-0.631458</td>\n      <td>0.636363</td>\n      <td>0.314424</td>\n      <td>0.246883</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.027273</td>\n      <td>-0.039302</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.022321</td>\n      <td>0.018182</td>\n      <td>-0.026549</td>\n      <td>-0.017391</td>\n      <td>-0.008621</td>\n      <td>0.022026</td>\n      <td>...</td>\n      <td>18.894266</td>\n      <td>0.803608</td>\n      <td>-0.277083</td>\n      <td>0.139086</td>\n      <td>-0.017547</td>\n      <td>0.579510</td>\n      <td>0.802806</td>\n      <td>0.490869</td>\n      <td>0.314424</td>\n      <td>0.261921</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 43 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model and local score\n\nA Random Forest (RF) model is chosen for the Benchmark. We consider a large number of tree with a quiet small depth. The missing values are simply filled with 0. A KFold is done on the dates (using `DATE`) for a local scoring of the model. \n\n**Ideas of improvements**: Tune the RF hyperparameters, deal with the missing values, change the features, consider another model, ...","metadata":{}},{"cell_type":"code","source":"X_train = train[features]\ny_train = train[target]\n\n# A quiet large number of trees with low depth to prevent overfits\nparams = {\n    'task':'train',\n    'objective': 'binary',\n    'metric': ['accuracy', 'logloss'],\n    'learning_rate': 0.01,\n    'feature_fraction': 0.7,\n    'max_depth': 8,\n    'num_iterations':1000, \n}\n\ntrain_dates = train['DATE'].unique()\ntest_dates = test['DATE'].unique()\n\nn_splits = 5\nscores = []\nmodels = []\n\nsplits = KFold(n_splits=n_splits, random_state=0,\n               shuffle=True).split(train_dates)\n\nfor i, (local_train_dates_ids, local_test_dates_ids) in enumerate(splits):\n    local_train_dates = train_dates[local_train_dates_ids]\n    local_test_dates = train_dates[local_test_dates_ids]\n\n    local_train_ids = train['DATE'].isin(local_train_dates)\n    local_test_ids = train['DATE'].isin(local_test_dates)\n\n    X_local_train = X_train.loc[local_train_ids]\n    y_local_train = y_train.loc[local_train_ids]\n    X_local_test = X_train.loc[local_test_ids]\n    y_local_test = y_train.loc[local_test_ids]\n\n    X_local_train = X_local_train.fillna(0)\n    X_local_test = X_local_test.fillna(0)\n    # modelling using lightGBM\n    model = lgb.LGBMClassifier(**params)\n    model.fit(X_local_train, y_local_train,\n              eval_set=[(X_local_test, y_local_test)],\n              eval_metric=[\"binary_error\", \"binary_logloss\"],\n              verbose=100,\n              early_stopping_rounds=100\n             )\n\n    y_local_pred = model.predict_proba(X_local_test)[:, 1]\n    \n    sub = train.loc[local_test_ids].copy()\n    sub['pred'] = y_local_pred\n    y_local_pred = sub.groupby('DATE')['pred'].transform(lambda x: x > x.median()).values\n\n    models.append(model)\n    score = accuracy_score(y_local_test, y_local_pred)\n    scores.append(score)\n    print(f\"Fold {i+1} - Accuracy: {score* 100:.2f}%\")\n\nmean = np.mean(scores)*100\nstd = np.std(scores)*100\nu = (mean + std)\nl = (mean - std)\nprint(f'Accuracy: {mean:.2f}% [{l:.2f} ; {u:.2f}] (+- {std:.2f})')","metadata":{"execution":{"iopub.status.busy":"2022-11-20T10:46:24.446880Z","iopub.execute_input":"2022-11-20T10:46:24.447326Z","iopub.status.idle":"2022-11-20T10:47:17.134493Z","shell.execute_reply.started":"2022-11-20T10:46:24.447283Z","shell.execute_reply":"2022-11-20T10:47:17.133561Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[100]\tvalid_0's binary_error: 0.477985\tvalid_0's binary_logloss: 0.692347\n[200]\tvalid_0's binary_error: 0.476353\tvalid_0's binary_logloss: 0.692014\n[300]\tvalid_0's binary_error: 0.474031\tvalid_0's binary_logloss: 0.691995\nFold 1 - Accuracy: 52.78%\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[100]\tvalid_0's binary_error: 0.487198\tvalid_0's binary_logloss: 0.692895\nFold 2 - Accuracy: 51.66%\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[100]\tvalid_0's binary_error: 0.492954\tvalid_0's binary_logloss: 0.693214\nFold 3 - Accuracy: 50.78%\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[100]\tvalid_0's binary_error: 0.484655\tvalid_0's binary_logloss: 0.692561\nFold 4 - Accuracy: 51.67%\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[100]\tvalid_0's binary_error: 0.486581\tvalid_0's binary_logloss: 0.692941\nFold 5 - Accuracy: 51.55%\nAccuracy: 51.69% [51.05 ; 52.33] (+- 0.64)\n","output_type":"stream"}]},{"cell_type":"code","source":"feature_importances = pd.DataFrame([model.feature_importances_ for model in models], columns=features)\n\nsns.barplot(data=feature_importances)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T10:47:17.135882Z","iopub.execute_input":"2022-11-20T10:47:17.136636Z","iopub.status.idle":"2022-11-20T10:47:18.694528Z","shell.execute_reply.started":"2022-11-20T10:47:17.136589Z","shell.execute_reply":"2022-11-20T10:47:18.691221Z"},"trusted":true},"execution_count":136,"outputs":[{"execution_count":136,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"## Generate the submission\n\nThe same parameters of the RF model are considered. With that we build a new RF model on the entire `train` dataset. The predictions are saved in a `.csv` file.","metadata":{}},{"cell_type":"code","source":"X_test = test[features]\n\nparams['random_state'] = 0\nmodel = lgb.LGBMClassifier(**params)\nmodel.fit(X_train.fillna(0), y_train, verbose=100,)\ny_pred_lgb = model.predict_proba(X_test.fillna(0))[:, 1]\nrf_params = {\n    'n_estimators': 500,\n    'max_depth': 2**3,\n    'random_state': 0,\n    'n_jobs': -1\n}\nmodel = RandomForestClassifier(**rf_params)\nmodel.fit(X_train.fillna(0), y_train)\ny_pred_rf = model.predict_proba(X_test.fillna(0))[:, 1]\nsub = test.copy()\nsub['pred'] = (y_pred_rf*0.5)+(y_pred_lgb*0.5)\ny_pred = sub.groupby('DATE')['pred'].transform(\n    lambda x: x > x.median()).values\n\nsubmission = pd.Series(y_pred)\nsubmission.index = test.index\nsubmission.name = target\n\nsubmission.to_csv('./Stock_Return_Prediction_Model_using_Machine_Learning.csv', index=True, header=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-20T11:04:48.545952Z","iopub.execute_input":"2022-11-20T11:04:48.546442Z","iopub.status.idle":"2022-11-20T11:13:18.830833Z","shell.execute_reply.started":"2022-11-20T11:04:48.546400Z","shell.execute_reply":"2022-11-20T11:13:18.829711Z"},"trusted":true},"execution_count":138,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\nThe local accuracy is around 51. If we did not overfit, we shall expect something within the range above.\n\nAfter submitting the benchmark file at https://challengedata.ens.fr, we obtain a public score of 51.31 %.","metadata":{}}]}